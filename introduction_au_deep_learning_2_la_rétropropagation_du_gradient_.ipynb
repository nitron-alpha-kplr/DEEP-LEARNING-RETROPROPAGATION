{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn0a1DUaIauNXXC+RrtATr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitron-alpha-kplr/DEEP-LEARNING-RETROPROPAGATION/blob/main/introduction_au_deep_learning_2_la_r%C3%A9tropropagation_du_gradient_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python mnist2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i_FjHW1LF83",
        "outputId": "9d60b42a-7fb9-4e0f-d44c-5bf32cc67ea6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/mnist2.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.datasets import fetch_mldata\n",
        "\n",
        "DATA_PATH = 'data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "zCQuaV2bL59f",
        "outputId": "54f8e4ab-4dd1-4f00-8a2c-ec6d40755687"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-371e95f56515>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'fetch_mldata' from 'sklearn.datasets' (/usr/local/lib/python3.10/dist-packages/sklearn/datasets/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_data():\n",
        "    \"\"\"Easy way to fetch and prepare mnist data.\"\"\"\n",
        "    mnist = fetch_mldata('MNIST original', data_home=DATA_PATH)\n",
        "\n",
        "    # Dans MNIST, les données sont triées par labels (les 0 d'abord, les 1\n",
        "    # ensuite…), ce qui ne nous convient pas. Mélangeons-les.\n",
        "    X, y = shuffle(mnist.data, mnist.target)\n",
        "\n",
        "    # X est une matrice de taille(70000, 784)\n",
        "    # X[0] est la première image de la liste\n",
        "    # X[0][0] est le premier pixel de cette image\n",
        "    # y est une matrice de taille (70000,)\n",
        "    # y[0] est la valeur représentée par l'image X[0]\n",
        "\n",
        "    # Comme les valeurs des pixels sont exprimées entre 0 et 255, nous divisons\n",
        "    # par 255 pour obtenir des valeurs comprises entre 0 et 1.\n",
        "    return X / 255.0, y"
      ],
      "metadata": {
        "id": "bFwr5-4xMD7f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    \"\"\"Dérivée de la fonction sigmoid.\"\"\"\n",
        "    return sigmoid(x) * (1.0 - sigmoid(x))"
      ],
      "metadata": {
        "id": "D_v3gOECMMQm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def to_one_hot(y, k):\n",
        "    \"\"\"Convertit un entier en vecteur \"one-hot\".\n",
        "\n",
        "    to_one_hot(5, 10) -> (0, 0, 0, 0, 1, 0, 0, 0, 0)\n",
        "\n",
        "    \"\"\"\n",
        "    one_hot = np.zeros(k)\n",
        "    one_hot[y] = 1\n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "M5qJK4yXMTT4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    \"\"\"Une seule couche de neurones.\"\"\"\n",
        "    def __init__(self, size, input_size):\n",
        "        self.size = size\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Les poids sont représentés par une matrice de n lignes\n",
        "        # et m colonnes. n = le nombre de neurones, m = le nombre de\n",
        "        # neurones dans la couche précédente.\n",
        "        self.weights = np.random.randn(size, input_size)\n",
        "\n",
        "        # Un biais par neurone\n",
        "        self.biases = np.random.randn(size)\n",
        "\n",
        "    # Résultat du calcul de chaque neurone.\n",
        "    # Il est important de noter que `data` est un vecteur (normalement, de\n",
        "    # longueur `self.input_size`, et que nous retournons un vecteur de\n",
        "    # taille `self.size`.\n",
        "    def forward(self, data):\n",
        "        aggregation = self.aggregation(data)\n",
        "        activation = self.activation(aggregation)\n",
        "        return activation\n",
        "\n",
        "    # Calcule la somme des entrées pondérées + biais pour chaque neurone.\n",
        "    # Plutôt que d'utiliser une boucle for, nous tirons parti du calcul\n",
        "    # matriciel qui permet d'effectuer toutes ces opérations d'un coup.\n",
        "    def aggregation(self, data):\n",
        "        return np.dot(self.weights, data) + self.biases\n",
        "\n",
        "    # Passe les valeurs aggrégées dans la moulinette de la fonction\n",
        "    # d'activation.\n",
        "    # `x` est un vecteur de longueur `self.size`, et nous retournons un\n",
        "    # vecteur de même dimension.\n",
        "    def activation(self, x):\n",
        "        return sigmoid(x)"
      ],
      "metadata": {
        "id": "7CSpN_nNMXOp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Dérivée de la fonction d'activation.\n",
        "    def activation_prime(self, x):\n",
        "        return sigmoid_prime(x)\n",
        "\n",
        "    # Mise à jour des poids à partir du gradient (algo du gradient)\n",
        "    def update_weights(self, gradient, learning_rate):\n",
        "        self.weights -= learning_rate * gradient\n",
        "\n",
        "    # Idem mais avec les biais\n",
        "    def update_biases(self, gradient, learning_rate):\n",
        "        self.biases -= learning_rate * gradient"
      ],
      "metadata": {
        "id": "O5_iLC5-MdXQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "    \"\"\"Un réseau constitué de couches de neurones.\"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.layers = []\n",
        "\n",
        "    def add_layer(self, size):\n",
        "        if len(self.layers) > 0:\n",
        "            input_dim = self.layers[-1].size\n",
        "        else:\n",
        "            input_dim = self.input_dim\n",
        "\n",
        "        self.layers.append(Layer(size, input_dim))"
      ],
      "metadata": {
        "id": "NRG_l59QMlMI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Propage les données d'entrée d'une couche à l'autre.\n",
        "    def feedforward(self, input_data):\n",
        "        activation = input_data\n",
        "        for layer in self.layers:\n",
        "            activation = layer.forward(activation)\n",
        "        return activation"
      ],
      "metadata": {
        "id": "ugnvPE3oMojw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Retourne l'index du neurone de sortie qui a la plus haute valeur, ce\n",
        "    # qui revient à indiquer quelle classe est sélectionnée par le réseau.\n",
        "    def predict(self, input_data):\n",
        "        return np.argmax(self.feedforward(input_data))"
      ],
      "metadata": {
        "id": "ALpDmBaZMuAw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   # Évalue la performance du réseau à partir d'un set d'exemples.\n",
        "    # Retourne un nombre entre 0 et 1.\n",
        "    def evaluate(self, X, Y):\n",
        "        results = [1 if self.predict(x) == y else 0 for (x, y) in zip(X, Y)]\n",
        "        accuracy = sum(results) / len(results)\n",
        "        return accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "-52jZdq7MxQy",
        "outputId": "cc9934ab-93be-4013-b640-d39488cc4c0e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-e125b9898fe7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def evaluate(self, X, Y):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   # Fonction d'entraînement du modèle.\n",
        "    # Comme décrit dans le billet, nous allons faire tourner la\n",
        "    # rétropropagation sur un certain nombre d'exemples (batch_size) avant\n",
        "    # de calculer un gradient moyen, et de mettre à jour les poids.\n",
        "    def train(self, X, Y, steps=30, learning_rate=0.3, batch_size=10):\n",
        "        n = Y.size\n",
        "        for i in range(steps):\n",
        "            # Mélangeons les données parce que… parce que.\n",
        "            X, Y = shuffle(X, Y)\n",
        "            for batch_start in range(0, n, batch_size):\n",
        "                X_batch, Y_batch = X[batch_start:batch_start + batch_size], Y[batch_start:batch_start + batch_size]\n",
        "                self.train_batch(X_batch, Y_batch, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "_15w47TMM1mB",
        "outputId": "2e14fdad-aa8d-46d0-d721-00fecc03303c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-e5c25d8eb03e>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def train(self, X, Y, steps=30, learning_rate=0.3, batch_size=10):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Cette fonction combine les algos du retropropagation du gradient +\n",
        "    # gradient descendant.\n",
        "    def train_batch(self, X, Y, learning_rate):\n",
        "        # Initialise les gradients pour les poids et les biais.\n",
        "        weight_gradient = [np.zeros(layer.weights.shape) for layer in self.layers]\n",
        "        bias_gradient = [np.zeros(layer.biases.shape) for layer in self.layers]\n",
        "\n",
        "        # On fait tourner l'algo de rétropropagation pour calculer les\n",
        "        # gradients un certain nombre de fois. On fera la moyenne ensuite.\n",
        "        for (x, y) in zip(X, Y):\n",
        "            new_weight_gradient, new_bias_gradient = self.backprop(x, y)\n",
        "            weight_gradient = [wg + nwg for wg, nwg in zip(weight_gradient, new_weight_gradient)]\n",
        "            bias_gradient = [bg + nbg for bg, nbg in zip(bias_gradient, new_bias_gradient)]\n",
        "\n",
        "        # C'est ici qu'on calcule les moyennes des gradients calculés\n",
        "        avg_weight_gradient = [wg / Y.size for wg in weight_gradient]\n",
        "        avg_bias_gradient = [bg / Y.size for bg in bias_gradient]\n",
        "\n",
        "        # Il ne reste plus qu'à mettre à jour les poids et biais en\n",
        "        # utilisant l'algo du gradient descendant.\n",
        "        for layer, weight_gradient, bias_gradient in zip(self.layers,\n",
        "                                                         avg_weight_gradient,\n",
        "                                                         avg_bias_gradient):\n",
        "            layer.update_weights(weight_gradient, learning_rate)\n",
        "            layer.update_biases(bias_gradient, learning_rate)"
      ],
      "metadata": {
        "id": "TBw2jjZOM5Cq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # L'algorithme de rétropropagation du gradient.\n",
        "    # C'est là que tout le boulot se fait.\n",
        "    def backprop(self, x, y):\n",
        "\n",
        "        # On va effectuer une passe vers l'avant, une passe vers l'arrière\n",
        "        # On profite de la passe vers l'avant pour stocker les calculs\n",
        "        # intermédiaires, qui seront réutilisés par la suite.\n",
        "        aggregations = []\n",
        "        activation = x\n",
        "        activations = [activation]\n",
        "\n",
        "        # Propagation pour obtenir la sortie\n",
        "        for layer in self.layers:\n",
        "            aggregation = layer.aggregation(activation)\n",
        "            aggregations.append(aggregation)\n",
        "            activation = layer.activation(aggregation)\n",
        "            activations.append(activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "5MCFRkbXNGSY",
        "outputId": "4abd67e3-5a84-4f6b-9c45-ae6b500affe6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-ef26a37aed8b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def backprop(self, x, y):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "        # Calculons la valeur delta (δ) pour la dernière couche\n",
        "        # en appliquant les équations détaillées plus haut.\n",
        "        target = to_one_hot(int(y), 10)\n",
        "        delta = self.get_output_delta(aggregation, activation, target)\n",
        "        deltas = [delta]\n",
        "\n",
        "        # Phase de rétropropagation pour calculer les deltas de chaque\n",
        "        # couche\n",
        "        # On utilise une implémentation vectorielle des équations.\n",
        "        nb_layers = len(self.layers)\n",
        "        for l in reversed(range(nb_layers - 1)):\n",
        "            layer = self.layers[l]\n",
        "            next_layer = self.layers[l + 1]\n",
        "            activation_prime = layer.activation_prime(aggregations[l])\n",
        "            delta = activation_prime * np.dot(next_layer.weights.transpose(), delta)\n",
        "            deltas.append(delta)\n",
        "\n",
        "        # Nous sommes parti de l'avant-dernière couche pour remonter vers\n",
        "        # la première. deltas[0] contient le delta de la dernière couche.\n",
        "        # Nous l'inversons pour faciliter la gestion des indices plus tard.\n",
        "        deltas = list(reversed(deltas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "3NEwLpw1NOyB",
        "outputId": "406693fb-c03e-4b24-d29f-9d530c713f2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b1ef26027a2f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculons la valeur delta (δ) pour la dernière couche\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# en appliquant les équations détaillées plus haut.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "     # On utilise maintenant les deltas pour calculer les gradients.\n",
        "        weight_gradient = []\n",
        "        bias_gradient = []\n",
        "        for l in range(len(self.layers)):\n",
        "\n",
        "            # Notez que l'indice des activations est « décalé », puisque\n",
        "            # activation[0] contient l'entrée (x), et pas l'activation de\n",
        "            # la première couche.\n",
        "            prev_activation = activations[l]\n",
        "            weight_gradient.append(np.outer(deltas[l], prev_activation))\n",
        "            bias_gradient.append(deltas[l])\n",
        "\n",
        "        return weight_gradient, bias_gradient\n",
        "\n",
        "    # Calcule le delta pour la dernière couche, en utilisant\n",
        "    # les dernières valeurs d'aggregation, d'activation, et la valeur\n",
        "    # cible.\n",
        "    # Notez que lorsque l'on utilise l'entropie croisée pour fonction de\n",
        "    # coût, l'équation de calcul de delta peut-être simplifiée pour aboutir\n",
        "    # au résultat ci dessous.\n",
        "    # Cf http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function\n",
        "    def get_output_delta(self, z, a, target):\n",
        "        return a - target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "EvDpOu9NNYjS",
        "outputId": "6fe149fd-1640-453b-9b73-f96e3f3ef13f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-40cbe1375834>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    weight_gradient = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    # Découpons notre base de données en deux.\n",
        "    # Une partie pour l'entraînement du réseau, l'autre pour vérifier\n",
        "    # sa performance.\n",
        "    X, Y = load_mnist_data()\n",
        "    X_train, Y_train = X[:60000], Y[:60000]\n",
        "    X_test, Y_test = X[60000:], Y[60000:]\n",
        "\n",
        "    net = Network(input_dim=784)\n",
        "    net.add_layer(200)\n",
        "    net.add_layer(10)\n",
        "\n",
        "    accuracy = net.evaluate(X_test, Y_test)\n",
        "    print('Performance initiale : {:.2f}%'.format(accuracy * 100.0))\n",
        "\n",
        "    for i in range(30):\n",
        "        net.train(X_train, Y_train, steps=1, learning_rate=3.0)\n",
        "        accuracy = net.evaluate(X_test, Y_test)\n",
        "        print('Nouvelle performance : {:.2f}%'.format(accuracy * 100.0))"
      ],
      "metadata": {
        "id": "36cbC0fpNllJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}